{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4754e7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.11.9)\n",
      "Requirement already satisfied: pytesseract in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: pdf2image in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: PyMuPDF in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.7)\n",
      "Requirement already satisfied: pdfminer.six==20251230 in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pdfplumber) (20251230)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pdfplumber) (10.4.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pdfplumber) (5.3.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pdfminer.six==20251230->pdfplumber) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pdfminer.six==20251230->pdfplumber) (46.0.3)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\naker\\appdata\\roaming\\python\\python312\\site-packages (from pytesseract) (26.0)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (2.23)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pdfplumber pytesseract pdf2image  PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "454dfd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import fitz\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d4b96929",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extractTextFromPdf():\n",
    "    text=\"\"\n",
    "    doc = fitz.open('MadhaviNakirikanti.pdf')\n",
    "    for page in doc:\n",
    "        pagetxt = page.get_text()\n",
    "        if pagetxt:\n",
    "            text = text+page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7ae3548e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U google-genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ac0fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f3ad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resumeAnalyzer(base_prompt):\n",
    "     client = genai.Client()\n",
    "     chat = client.chats.create(model=\"gemini-3-flash-preview\")\n",
    "\n",
    "     response = chat.send_message(base_prompt)\n",
    "     print(response.text)\n",
    "     data = json.loads(response.text)\n",
    "     return data\n",
    "     \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4bfedd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madhavi Nakirikanti \n",
      "Software Developer \n",
      "Email: madhavinakirikanti22@gmail.com \n",
      "LinkedIn: https://www.linkedin.com/in/madhavi-nakirikanti-602773308/ \n",
      " \n",
      "Summary: \n",
      "Software Engineer with ~4 years of experience delivering scalable platform and backend solutions using Java, Spring Boot, React, and \n",
      "AWS. Experienced in building secure APIs, data pipelines, and cloud-based services that support business-critical workflows. Adept at \n",
      "working in agile, product-oriented teams to deliver reliable, data-driven systems that directly impact customer experience and business \n",
      "outcomes. \n",
      " \n",
      "Technical Skills: \n",
      " \n",
      " \n",
      " \n",
      "Professional Experience \n",
      "Amazon  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " Duration: June 2025 - Present \n",
      "Role: Software Developer II \n",
      "Responsibilities: \n",
      " \n",
      "• \n",
      "Designed and shipped high-throughput backend services for Amazon Stores using Java 17 and Spring Boot, supporting \n",
      "critical workflows with strict latency and reliability requirements. \n",
      "• \n",
      "Built and standardized REST APIs with strong validation, exception handling, and backward compatibility, enabling safe \n",
      "adoption across multiple dependent services. \n",
      "• \n",
      "Developed large-scale AWS Glue ETL pipelines processing data from Amazon S3, enabling downstream analytics and \n",
      "reporting for business stakeholders. \n",
      "• \n",
      "Architected an S3-based data lake with partitioning and lifecycle policies, improving query performance while reducing \n",
      "storage costs. \n",
      "• \n",
      "Implemented event-driven and batch workflows integrating S3 events, Glue, and Lambda, ensuring fault-tolerant data \n",
      "processing. \n",
      "• \n",
      "Deployed and operated services on ECS and Kubernetes, achieving high availability and zero-downtime deployments. \n",
      "• \n",
      "Integrated Apache Kafka for asynchronous messaging, decoupling producers and consumers across distributed systems. \n",
      "• \n",
      "Introduced Redis caching to reduce database load and significantly improve API response latency under peak traffic. \n",
      "• \n",
      "Owned production monitoring and on-call readiness, using CloudWatch logs, metrics, and alarms to proactively detect \n",
      "and resolve issues. \n",
      "• \n",
      "Improved code quality and long-term maintainability by writing unit and integration tests with JUnit and Mockito. \n",
      " \n",
      "Programming Languages \n",
      "Java (17+), JavaScript (ES6+), TypeScript, Python, C#, .NET \n",
      "Databases \n",
      "PostgreSQL, Oracle, MS SQL Server, MongoDB, RedShift, Dynamo DB \n",
      "Backend & Frameworks \n",
      " \n",
      " \n",
      "Spring Boot, Spring MVC, Spring Data JPA, Spring Security, Spring Cloud, Spring \n",
      "Batch, OAuth 2.0, JWT, Apache Kafka, Node.js \n",
      "Data & ETL \n",
      " \n",
      "AWS Glue (ETL, data transformation), Amazon S3 (data lakes, partitioning), \n",
      "Snowflake (Data Warehousing, SQL) \n",
      "CI/CD & Build Tools \n",
      " \n",
      "Maven, npm, Yarn, GitHub Actions, GitLab CI/CD \n",
      " \n",
      "Web Technologies \n",
      " \n",
      "HTML, CSS, XML, JSON, SOAP, WSDL, REST, JSP, React js, javaScript, Angular \n",
      "js \n",
      "Web/Application Servers \n",
      "Apache Tomcat, JBoss, IBM WebSphere, Oracle WebLogic Server 14+, JVM, \n",
      "Graph \n",
      "Cloud Technologies \n",
      "AWS (EC2, ECS, S3, Glue, Athena, API Gateway, Lambda), Docker, Kubernetes, \n",
      "IAM, CloudWatch, CloudFormation \n",
      " \n",
      "Testing Tools \n",
      "Cypress, Jasmine, Selenium, Chai, Protractor, Junit, Mockitio \n",
      "Monitoring & Observability \n",
      "Splunk, metric, cloud watch \n",
      "Agile Methodologies \n",
      "Sprint Planning, Development, Testing, and Deployment \n",
      "Zemoso Technologies \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Duration: Oct 2020- Dec 2022 \n",
      "Role: Software Developer \n",
      " \n",
      "Responsibilities: \n",
      "• \n",
      "Owned full stack features end-to-end, building scalable web applications using React, Java, and Spring Boot. \n",
      "• \n",
      "Designed RESTful APIs and integrated OAuth 2.0 / JWT, enabling secure communication between frontend and backend \n",
      "services. \n",
      "• \n",
      "Built reusable React components and shared UI patterns, accelerating feature development across projects. \n",
      "• \n",
      "Optimized database queries and schemas using PostgreSQL, improving performance under high-volume traffic. \n",
      "• \n",
      "Automated CI/CD pipelines, reducing manual deployment effort and improving release reliability \n",
      "• \n",
      "Containerized services using Docker and deployed to cloud environments for scalable production usage \n",
      "NCR Corporation                                                                                                                     \n",
      " \n",
      "Duration: Jan 2020 - Oct 2020 \n",
      "Role: Associate Software Developer \n",
      " \n",
      "Responsibilities: \n",
      "• \n",
      "Developed Java-based backend services for banking and payment validation workflows with strict accuracy requirements. \n",
      "• \n",
      "Implemented validation, exception handling, and audit logging, ensuring compliance with financial standards. \n",
      "• \n",
      "Built and tested REST APIs using Spring and JUnit, improving system reliability. \n",
      " \n",
      "EDUCATION: \n",
      "Master’s in computer science - 2024 \n",
      "University of North Texas, Texas, USA \n",
      "Bachelor’s in computer science- 2020 \n",
      "Shri Vishnu Engineering College from Women, India \n",
      " \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "resume_text = extractTextFromPdf()\n",
    "print(resume_text)\n",
    "job_description=\"\"\" Responsibilities\n",
    "\n",
    "Architect, design, and implement scalable software solutions that support core ACES functionalities.\n",
    "Develop intelligent agentic systems capable of autonomous decision-making and task execution.\n",
    "Build and optimize AI agents using AI Foundry, Python, and reinforcement learning techniques.\n",
    "Develop full stack applications with a strong emphasis on backend services using C# and cloud-native technologies.\n",
    "Design and implement synthetic data generation pipelines to support training and evaluation of agentic models.\n",
    "Collaborate with product managers, researchers, and engineering teams to define technical requirements and deliver innovative solutions.\n",
    "Drive technical excellence through mentorship, code reviews, and adoption of best practices.\n",
    "Own the end-to-end lifecycle of software components, including design, development, testing, deployment, and maintenance.\n",
    "Contribute to architectural decisions, scalability strategies, and long-term technical vision. Evaluate and integrate emerging technologies to enhance platform capabilities.\n",
    "Ensure high standards of software quality, performance, and security.\n",
    "\n",
    "Qualifications\n",
    "\n",
    "Minimum Qualifications:\n",
    "\n",
    "Bachelor's Degree in Computer Science, Engineering, Data Science, Math, Business, or related field AND 2+ years experience in engineering, product/technical program management, data analysis, or product development OR equivalent experience. \n",
    "2+ years of experience in software development, with a track record of delivering complex systems.\n",
    "2+ years of experience Python and C# with experience in AI/ML and full stack development.\n",
    "Hands-on experience with AI Foundry, agentic systems, and reinforcement learning.\n",
    "\n",
    "Other Requirements\n",
    "\n",
    "Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to, the following specialized security screenings:\n",
    "\n",
    "Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.\n",
    "\n",
    "Preferred Qualifications\n",
    "\n",
    "Master's Degree in Engineering, or related field AND 3+ years experience in technology industry, cloud, technical support, and/or customer experience engineering OR Bachelor's Degree in Engineering, Computer Science, Information Technology (IT), Data Analytics/Science, Artificial Intelligence (AI), or related field AND 8+ years experience in technology industry, cloud, technical support, and/or customer experience engineering OR equivalent experience.\n",
    "2+ years of customer facing experience.\n",
    "3+ years of experience of data structures, algorithms, system design, and distributed computing.\n",
    "3+ years of experience with cloud platforms (Azure, Google Cloud, AWS, etc.) and microservices architecture.\n",
    "Experience with CI/CD pipelines, DevOps practices, and container orchestration (e.g., Kubernetes).\n",
    "Expertise in synthetic data generation, simulation environments, and AI evaluation frameworks.\n",
    "Proven leadership in driving technical initiatives and mentoring engineering teams.\n",
    "Problem-solving skills and ability to thrive in a fast-paced, collaborative environment.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "aa62de64",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = prompt = f\"\"\"\n",
    "You are an expert resume writer and ATS optimization specialist.\n",
    "\n",
    "Task:\n",
    "1) Read the RESUME and JOB DESCRIPTION.\n",
    "2) Rewrite the resume so it matches the JD 100%.\n",
    "3) Add missing skills ONLY if they are reasonable given the candidate’s existing background.\n",
    "   - If not present in resume, you may add as \"Familiar\" or \"Basic\" but do NOT invent work experience.\n",
    "4) Improve bullet points with impact + metrics when possible.\n",
    "5) Keep output ATS-friendly (no tables, no icons, no columns).\n",
    "6) Output STRICT JSON ONLY (no markdown).\n",
    "\n",
    "Return this JSON schema:\n",
    "{{\n",
    "  \"name\": \"\",\n",
    "  \"headline\": \"\",\n",
    "  \"contact\": \"\",\n",
    "  \"summary\": [\n",
    "    \"...\"\n",
    "  ],\n",
    "  \"skills\": {{\n",
    "    \"Programming Languages\": [\"...\"],\n",
    "    \"Backend/Cloud\": [\"...\"],\n",
    "    \"AI/ML\": [\"...\"],\n",
    "    \"Data/Tools\": [\"...\"],\n",
    "    \"DevOps\": [\"...\"]\n",
    "  }},\n",
    "  \"experience\": [\n",
    "    {{\n",
    "      \"title\": \"\",\n",
    "      \"company\": \"\",\n",
    "      \"location\": \"\",\n",
    "      \"dates\": \"\",\n",
    "      \"bullets\": [\"...\", \"...\", \"...\"]\n",
    "    }}\n",
    "  ],\n",
    "  \"projects\": [\n",
    "    {{\n",
    "      \"name\": \"\",\n",
    "      \"tech\": [\"...\"],\n",
    "      \"bullets\": [\"...\", \"...\"]\n",
    "    }}\n",
    "  ],\n",
    "  \"education\": [\n",
    "    {{\n",
    "      \"school\": \"\",\n",
    "      \"degree\": \"\",\n",
    "      \"location\": \"\",\n",
    "      \"dates\": \"\",\n",
    "      \"details\": [\"...\"]\n",
    "    }}\n",
    "  ],\n",
    "  \"certifications\": [\"...\"],\n",
    "  \"keywords_added\": [\"...\"]  // missing JD keywords you incorporated\n",
    "}}\n",
    "\n",
    "\n",
    "RESUME:\n",
    "{resume_text}\n",
    "\n",
    "JOB DESCRIPTION:\n",
    "{job_description}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "df762092",
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\\nPlease retry in 14.449585998s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-3-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[130]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m resumeres = \u001b[43mresumeAnalyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_prompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[116]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mresumeAnalyzer\u001b[39m\u001b[34m(base_prompt)\u001b[39m\n\u001b[32m      2\u001b[39m client = genai.Client()\n\u001b[32m      3\u001b[39m chat = client.chats.create(model=\u001b[33m\"\u001b[39m\u001b[33mgemini-3-flash-preview\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m response = \u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.text)\n\u001b[32m      7\u001b[39m data = json.loads(response.text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\naker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\genai\\chats.py:252\u001b[39m, in \u001b[36mChat.send_message\u001b[39m\u001b[34m(self, message, config)\u001b[39m\n\u001b[32m    247\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    248\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMessage must be a valid part type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes.PartUnion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m or\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    249\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes.PartUnionDict\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(message)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    250\u001b[39m   )\n\u001b[32m    251\u001b[39m input_content = t.t_content(message)\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_modules\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_curated_history\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_content\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    257\u001b[39m model_output = (\n\u001b[32m    258\u001b[39m     [response.candidates[\u001b[32m0\u001b[39m].content]\n\u001b[32m    259\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response.candidates \u001b[38;5;129;01mand\u001b[39;00m response.candidates[\u001b[32m0\u001b[39m].content\n\u001b[32m    260\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[32m    261\u001b[39m )\n\u001b[32m    262\u001b[39m automatic_function_calling_history = (\n\u001b[32m    263\u001b[39m     response.automatic_function_calling_history\n\u001b[32m    264\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response.automatic_function_calling_history\n\u001b[32m    265\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[32m    266\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\naker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\genai\\models.py:5474\u001b[39m, in \u001b[36mModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5472\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc > \u001b[32m0\u001b[39m:\n\u001b[32m   5473\u001b[39m   i += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m5474\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5475\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparsed_config\u001b[49m\n\u001b[32m   5476\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5478\u001b[39m   function_map = _extra_utils.get_function_map(parsed_config)\n\u001b[32m   5479\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m function_map:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\naker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\genai\\models.py:4214\u001b[39m, in \u001b[36mModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   4211\u001b[39m request_dict = _common.convert_to_dict(request_dict)\n\u001b[32m   4212\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m4214\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4215\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   4216\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4218\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   4219\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4220\u001b[39m ):\n\u001b[32m   4221\u001b[39m   return_value = types.GenerateContentResponse(sdk_http_response=response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\naker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\genai\\_api_client.py:1386\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1376\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mrequest\u001b[39m(\n\u001b[32m   1377\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1378\u001b[39m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1381\u001b[39m     http_options: Optional[HttpOptionsOrDict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1382\u001b[39m ) -> SdkHttpResponse:\n\u001b[32m   1383\u001b[39m   http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1384\u001b[39m       http_method, path, request_dict, http_options\n\u001b[32m   1385\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1386\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1387\u001b[39m   response_body = (\n\u001b[32m   1388\u001b[39m       response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1389\u001b[39m   )\n\u001b[32m   1390\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m SdkHttpResponse(headers=response.headers, body=response_body)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\naker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\genai\\_api_client.py:1222\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1219\u001b[39m     retry = tenacity.Retrying(**retry_kwargs)\n\u001b[32m   1220\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\naker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tenacity\\__init__.py:470\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    468\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m470\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    471\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    472\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\naker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tenacity\\__init__.py:371\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    369\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\naker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tenacity\\__init__.py:413\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    411\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\naker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tenacity\\__init__.py:184\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\naker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\naker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\naker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tenacity\\__init__.py:473\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    471\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    472\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    475\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\naker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\genai\\_api_client.py:1199\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1191\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1192\u001b[39m   response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m   1193\u001b[39m       method=http_request.method,\n\u001b[32m   1194\u001b[39m       url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1197\u001b[39m       timeout=http_request.timeout,\n\u001b[32m   1198\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1199\u001b[39m   \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1200\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1201\u001b[39m       response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1202\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\naker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\genai\\errors.py:134\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    132\u001b[39m   response_json = response.body_segments[\u001b[32m0\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\naker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\genai\\errors.py:159\u001b[39m, in \u001b[36mAPIError.raise_error\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Raises an appropriate APIError subclass based on the status code.\u001b[39;00m\n\u001b[32m    146\u001b[39m \n\u001b[32m    147\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    156\u001b[39m \u001b[33;03m  APIError: For other error status codes.\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n\u001b[32m    161\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n",
      "\u001b[31mClientError\u001b[39m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\\nPlease retry in 14.449585998s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-3-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}"
     ]
    }
   ],
   "source": [
    "resumeres = resumeAnalyzer(base_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9a8a9556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-docx) (6.0.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-docx) (4.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ee57ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "from docx.oxml.ns import qn\n",
    "\n",
    "def add_section_header(doc, title: str):\n",
    "    p = doc.add_paragraph()\n",
    "    run = p.add_run(title.upper())\n",
    "    run.bold = True\n",
    "    run.font.size = Pt(12)\n",
    "    doc.add_paragraph(\"-\" * 60)\n",
    "\n",
    "def add_bullets(doc, bullets):\n",
    "    for b in bullets or []:\n",
    "        doc.add_paragraph(b.strip(), style=\"List Bullet\")\n",
    "\n",
    "def build_neat_resume_docx(resume: dict, out_path=\"Updated_Resume.docx\"):\n",
    "    doc = Document()\n",
    "\n",
    "    # Global font\n",
    "    style = doc.styles[\"Normal\"]\n",
    "    style.font.name = \"Calibri\"\n",
    "    style._element.rPr.rFonts.set(qn(\"w:eastAsia\"), \"Calibri\")\n",
    "    style.font.size = Pt(11)\n",
    "\n",
    "    # Header: Name\n",
    "    name = resume.get(\"name\", \"\").strip()\n",
    "    p = doc.add_paragraph()\n",
    "    r = p.add_run(name)\n",
    "    r.bold = True\n",
    "    r.font.size = Pt(18)\n",
    "    p.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "\n",
    "    # Headline\n",
    "    headline = resume.get(\"headline\", \"\").strip()\n",
    "    if headline:\n",
    "        p = doc.add_paragraph(headline)\n",
    "        p.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "\n",
    "    # Contact\n",
    "    contact = resume.get(\"contact\", \"\").strip()\n",
    "    if contact:\n",
    "        p = doc.add_paragraph(contact)\n",
    "        p.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "\n",
    "    doc.add_paragraph(\"\")\n",
    "\n",
    "    # Summary\n",
    "    summary = resume.get(\"summary\", [])\n",
    "    if summary:\n",
    "        add_section_header(doc, \"Summary\")\n",
    "        add_bullets(doc, summary)\n",
    "        doc.add_paragraph(\"\")\n",
    "\n",
    "    # Skills (neat, grouped)\n",
    "    skills = resume.get(\"skills\", {})\n",
    "    if skills:\n",
    "        add_section_header(doc, \"Technical Skills\")\n",
    "        for cat, items in skills.items():\n",
    "            if not items:\n",
    "                continue\n",
    "            line = f\"{cat}: \" + \", \".join(items)\n",
    "            pr = doc.add_paragraph()\n",
    "            pr.add_run(line)\n",
    "        doc.add_paragraph(\"\")\n",
    "\n",
    "    # Experience\n",
    "    exp = resume.get(\"experience\", [])\n",
    "    if exp:\n",
    "        add_section_header(doc, \"Experience\")\n",
    "        for e in exp:\n",
    "            title = e.get(\"title\", \"\").strip()\n",
    "            company = e.get(\"company\", \"\").strip()\n",
    "            location = e.get(\"location\", \"\").strip()\n",
    "            dates = e.get(\"dates\", \"\").strip()\n",
    "\n",
    "            header = f\"{title} | {company}\"\n",
    "            if location:\n",
    "                header += f\" — {location}\"\n",
    "            if dates:\n",
    "                header += f\" | {dates}\"\n",
    "\n",
    "            pr = doc.add_paragraph()\n",
    "            rr = pr.add_run(header)\n",
    "            rr.bold = True\n",
    "\n",
    "            add_bullets(doc, e.get(\"bullets\", []))\n",
    "            doc.add_paragraph(\"\")\n",
    "\n",
    "    # Projects\n",
    "    projects = resume.get(\"projects\", [])\n",
    "    if projects:\n",
    "        add_section_header(doc, \"Projects\")\n",
    "        for prj in projects:\n",
    "            pname = prj.get(\"name\", \"\").strip()\n",
    "            tech = prj.get(\"tech\", [])\n",
    "            header = pname + (f\" | Tech: {', '.join(tech)}\" if tech else \"\")\n",
    "\n",
    "            p = doc.add_paragraph()\n",
    "            r = p.add_run(header)\n",
    "            r.bold = True\n",
    "\n",
    "            add_bullets(doc, prj.get(\"bullets\", []))\n",
    "            doc.add_paragraph(\"\")\n",
    "\n",
    "    # Education\n",
    "    edu = resume.get(\"education\", [])\n",
    "    if edu:\n",
    "        add_section_header(doc, \"Education\")\n",
    "        for ed in edu:\n",
    "            school = ed.get(\"school\", \"\").strip()\n",
    "            location = ed.get(\"location\", \"\").strip()\n",
    "            degree = ed.get(\"degree\", \"\").strip()\n",
    "            dates = ed.get(\"dates\", \"\").strip()\n",
    "\n",
    "            line1 = school + (f\" — {location}\" if location else \"\")\n",
    "            p1 = doc.add_paragraph()\n",
    "            p1.add_run(line1).bold = True\n",
    "\n",
    "            line2 = degree + (f\" | {dates}\" if dates else \"\")\n",
    "            doc.add_paragraph(line2)\n",
    "\n",
    "            add_bullets(doc, ed.get(\"details\", []))\n",
    "            doc.add_paragraph(\"\")\n",
    "\n",
    "    # Certifications (optional)\n",
    "    certs = resume.get(\"certifications\", [])\n",
    "    if certs:\n",
    "        add_section_header(doc, \"Certifications\")\n",
    "        add_bullets(doc, certs)\n",
    "\n",
    "    doc.save(out_path)\n",
    "    return out_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c31b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: Updated_Resume.docx\n"
     ]
    }
   ],
   "source": [
    "# You already have resume_text from your extractTextFromPdf()\n",
    "# updated_json = generate_updated_resume_json(resume_text, job_description)\n",
    "\n",
    "docx_file = build_neat_resume_docx(resumeres, \"Updated_Resume.docx\")\n",
    "print(\"Created:\", docx_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d368fa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting anthropic\n",
      "  Downloading anthropic-0.79.0-py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.0.1)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anthropic) (4.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anthropic) (1.9.0)\n",
      "Collecting docstring-parser<1,>=0.15 (from anthropic)\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anthropic) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from anthropic)\n",
      "  Downloading jiter-0.13.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anthropic) (2.12.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anthropic) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anthropic) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->anthropic) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.25.0->anthropic) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.25.0->anthropic) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\naker\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.2)\n",
      "Downloading anthropic-0.79.0-py3-none-any.whl (405 kB)\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading jiter-0.13.0-cp312-cp312-win_amd64.whl (205 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: python-dotenv, jiter, docstring-parser, anthropic\n",
      "\n",
      "  Attempting uninstall: python-dotenv\n",
      "\n",
      "    Found existing installation: python-dotenv 1.0.1\n",
      "\n",
      "    Uninstalling python-dotenv-1.0.1:\n",
      "\n",
      "      Successfully uninstalled python-dotenv-1.0.1\n",
      "\n",
      "   ---------------------------------------- 0/4 [python-dotenv]\n",
      "   ---------------------------------------- 0/4 [python-dotenv]\n",
      "   ---------------------------------------- 0/4 [python-dotenv]\n",
      "   -------------------- ------------------- 2/4 [docstring-parser]\n",
      "   -------------------- ------------------- 2/4 [docstring-parser]\n",
      "   -------------------- ------------------- 2/4 [docstring-parser]\n",
      "   -------------------- ------------------- 2/4 [docstring-parser]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ------------------------------ --------- 3/4 [anthropic]\n",
      "   ---------------------------------------- 4/4 [anthropic]\n",
      "\n",
      "Successfully installed anthropic-0.79.0 docstring-parser-0.17.0 jiter-0.13.0 python-dotenv-1.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -U anthropic python-dotenv\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
